{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udDs_biH0n5U"
   },
   "source": [
    "#### Copyright 2020 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPY-OyyM0pSs"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\")\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    " https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psnUF-8c02o_"
   },
   "source": [
    "# Reformer: Image Generation [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lnRd_IoERdk"
   },
   "source": [
    "This notebook was designed to run on TPU.\n",
    "\n",
    "To use TPUs in Colab, click \"Runtime\" on the main menu bar and select Change runtime type. Set \"TPU\" as the hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PluCmWbZIpJ"
   },
   "outputs": [],
   "source": [
    "# Install JAX. This custom build raises the TPU timeout threshold, because the\n",
    "# default limit of 2 minutes is too short for sampling very long sequences.\n",
    "!gsutil cp gs://trax-ml/reformer/jaxlib-0.1.39-cp36-none-manylinux2010_x86_64.whl .\n",
    "!gsutil cp gs://trax-ml/reformer/jax-0.1.59-cp36-none-manylinux2010_x86_64.whl .\n",
    "!pip install --upgrade -q ./jaxlib-0.1.39-cp36-none-manylinux2010_x86_64.whl\n",
    "!pip install --upgrade -q ./jax-0.1.59-cp36-none-manylinux2010_x86_64.whl\n",
    "\n",
    "# Make sure the Colab Runtime is set to Accelerator: TPU.\n",
    "import requests\n",
    "import os\n",
    "if 'TPU_DRIVER_MODE' not in globals():\n",
    "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
    "  resp = requests.post(url)\n",
    "  TPU_DRIVER_MODE = 1\n",
    "\n",
    "# The following is required to use TPU Driver as JAX's backend.\n",
    "from jax.config import config\n",
    "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
    "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
    "print(config.FLAGS.jax_backend_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiPdBenoZwH6"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q gin git+https://github.com/google/trax.git@v1.2.3\n",
    "\n",
    "from tensorflow.compat.v1.io.gfile import GFile\n",
    "import gin\n",
    "import os\n",
    "import jax\n",
    "import trax\n",
    "from trax.models.beam_search import Search\n",
    "from trax.data.preprocessing import inputs\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyxRk75iaAap"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQ89jHCYfhpg"
   },
   "source": [
    "## Load example data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBvuw2h85WXE"
   },
   "outputs": [],
   "source": [
    "# Normally we train on the full imagenet64 training set, which is quite large so\n",
    "# we won't be loading it from this notebook. Instead, let's just load a few PNG\n",
    "# images to use in our data pipeline.\n",
    "DATA = []\n",
    "for i in range(8):\n",
    "  img = plt.imread(GFile('gs://trax-ml/reformer/img{}.png'.format(i), 'rb'))\n",
    "  # Convert from RGBA floating-point to RGB integer representation.\n",
    "  img = np.asarray(img[:, :, :3] * 255, dtype=np.int32)\n",
    "  DATA.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "oBZh0Q2UEiaB",
    "outputId": "d5adcac0-6f76-4c56-e6ef-74becaca87be"
   },
   "outputs": [],
   "source": [
    "# We can examine one of the images to make sure we've loaded it correctly.\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.axis('off')\n",
    "plt.imshow(DATA[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXjtCPxl3I82"
   },
   "outputs": [],
   "source": [
    "# We'll be using a pre-trained 12-layer Reformer model.\n",
    "# First, load the config (which sets all needed hyperparameters).\n",
    "!gsutil cp gs://trax-ml/reformer/imgnet64/config.gin ./config.gin\n",
    "gin.parse_config_file('./config.gin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhiTshPPbvLY"
   },
   "outputs": [],
   "source": [
    "# Now we construct a ReformerLM instance and load the pre-trained weights.\n",
    "# The 'predict' mode configures the model to accept single tokens at a time,\n",
    "# instead of feeding in a complete image all at once.\n",
    "model_infer = trax.models.ReformerLM(mode='predict')\n",
    "model_infer.init_from_file(\n",
    "    'gs://trax-ml/reformer/imgnet64/model.pkl', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY3hpgnI5Rgn"
   },
   "source": [
    "## Sample from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnzRPCzFqIVi"
   },
   "source": [
    "Now we're ready to sample from the pre-trained Reformer model. Unlike during training, sampling processes the images one pixel and channel value at a time. The TPU colab runtime has 8 cores so we can sample 8 images in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9ZetV91PujO"
   },
   "outputs": [],
   "source": [
    "sampling_decoder = Search(\n",
    "    trax.models.ReformerLM,\n",
    "    model_infer.weights,\n",
    "    temperature=1.0,\n",
    "    max_decode_len=32*64*3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOLawc5dB7QV"
   },
   "source": [
    "Sampling is an inherently serial process and will take up to 9 minutes to run. A good chunk of that time will be spent on JIT-compiling the code, though, so the code cell below will finish faster when re-run for a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "We9Jj9Rap3cB",
    "outputId": "10b6142b-11f1-414d-9b63-353f721a6a82"
   },
   "outputs": [],
   "source": [
    "flat_prompt = []\n",
    "for i, img in enumerate(DATA[:trax.fastmath.device_count()]):\n",
    "  img = img.reshape((-1, 64, 3))[:32, :, :]\n",
    "  flat_prompt.append(img.reshape((-1,)))\n",
    "prompt = np.stack(flat_prompt, 0)\n",
    "\n",
    "print(\"Prompt:\")\n",
    "plt.figure(figsize=(10, 10*8))\n",
    "for i in range(prompt.shape[0]):\n",
    "  plt.subplot(1, 8, i+1)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(prompt[i].reshape((-1, 64, 3)), aspect='equal')\n",
    "plt.show()\n",
    "\n",
    "seqs, scores = sampling_decoder.decode(targets_prefix=prompt, batch_size=8)\n",
    "\n",
    "print(\"Sampled completions:\")\n",
    "plt.figure(figsize=(10, 10*8))\n",
    "for i in range(prompt.shape[0]):\n",
    "  plt.subplot(1, 8, i+1)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(seqs[i, -1].reshape((-1, 64, 3)), aspect='equal')\n",
    "\n",
    "plt.figure(figsize=(10, 10*8))\n",
    "for i in range(prompt.shape[0]):\n",
    "  plt.subplot(1, 8, i+1)\n",
    "  plt.axis('off')\n",
    "  img = jnp.concatenate([prompt[i], seqs[i, -1]], -1)\n",
    "  plt.imshow(img.reshape((-1, 64, 3)), aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "olF4PpORpCTK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "udDs_biH0n5U"
   ],
   "name": "Reformer: Image Generation",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
