defaults:
  - /data/modern_bert/modern_bert
  - _self_

data:
  # Phase 1 (pretraining): Large model, max seq len 1,024.
  # ModernBERT Large pretraining per Table 3 in the paper.
  # Batch size 4,928 with microbatch 56 => packed_batch_size 88.
  max_seq_len: 1024
  micro_batch_size: 56
  packed_batch_size: 88
  mlm_probability_train: 0.30
  mlm_probability_eval: 0.30

  make_streams:
    _target_: "trax.data.make_streams"
    train_stream:
      - "${data.train.LoadDataset}"
      - "${data.SelectTextField}"
      - "${data.ModernBertTokenize}"
      - "${data.ModernBertAppendDocBoundaryTokens}"
      - "${data.ChunkFixedLength}"
      - "${data.Shuffle}"
      - "${data.BatchToSrcBatch}"
      - "${data.ModernBertSequencePackerTrain}"
      - "${data.AddPositionIds}"
      - "${data.ToModelTuple}"
    eval_stream:
      - "${data.eval.LoadDataset}"
      - "${data.SelectTextField}"
      - "${data.ModernBertTokenize}"
      - "${data.ModernBertAppendDocBoundaryTokens}"
      - "${data.ChunkFixedLength}"
      - "${data.BatchToSrcBatch}"
      - "${data.ModernBertSequencePackerEval}"
      - "${data.AddPositionIds}"
      - "${data.ToModelTuple}"

  train:
    LoadDataset:
      _target_: "trax.data.TFDS"
      dataset_name: "wikipedia/20220301.en"
      data_dir: null
      keys:
        - "text"
      train: true
      shuffle_train: true

  eval:
    LoadDataset:
      _target_: "trax.data.TFDS"
      dataset_name: "wikipedia/20220301.en"
      data_dir: null
      keys:
        - "text"
      train: false
      shuffle_train: false

  SelectTextField:
    _target_: "trax.data.SelectTextField"
    field: "text"
    output_key: "text"
