defaults:
  - /data/base
  - _self_

data:
  make_streams:
    _target_: "trax.data.make_streams"
    _partial_: true
    train_stream:
      - "${data.train.TFDS}"
      - "${data.GenericTextPreprocess}"
      - "${data.Shuffle}"
      - "${data.BatchTrain}"
      - "${data.AddLossWeights}"
    eval_stream:
      - "${data.eval.TFDS}"
      - "${data.GenericTextPreprocess}"
      - "${data.Shuffle}"
      - "${data.BatchEval}"
      - "${data.AddLossWeights}"
  train:
    TFDS:
      _target_: "trax.data.TFDS"
      dataset_name: "imdb_reviews"
      data_dir: null
      train: true
  eval:
    TFDS:
      _target_: "trax.data.TFDS"
      dataset_name: "imdb_reviews"
      data_dir: null
      train: false
  BatchTrain:
    _target_: "trax.data.Batch"
    batch_size: 16
  BatchEval:
    _target_: "trax.data.Batch"
    batch_size: 16
  AddLossWeights:
    _target_: "trax.data.add_loss_weights"
    _partial_: true
  FilterByLengthMap:
    _target_: "trax.data.FilterByLengthMap"
    len_map:
      inputs: "(1, 512)"
    filter_on_eval: true
  TruncateByLengthMap:
    _target_: "trax.data.TruncateByLengthMap"
    len_map:
      inputs: 512
    truncate_on_eval: true
  PadToLengthMap:
    _target_: "trax.data.PadToLengthMap"
    len_map:
      inputs: 512
  GenericTextPreprocess:
    _target_: "trax.data.GenericTextPreprocess"
    spm_path: "gs://t5-data/vocabs/cc_all.32000/sentencepiece.model"
    text_preprocess_fns:
      - "${data.Rekey}"
    token_preprocess_fns:
      - "${data.TruncateByLengthMap}"
      - "${data.FilterByLengthMap}"
      - "${data.PadToLengthMap}"
  Rekey:
    _target_: "trax.data.Rekey"
    key_map:
      inputs: "text"
      targets: "label"
