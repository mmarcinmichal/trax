defaults:
  - /data/base
  - _self_

data:
  Tokenize:
    _target_: "trax.data.Tokenize"
    keys:
      - 0
      - 1
    vocab_file: "en_32k.subword"
  make_inputs:
    _target_: "trax.data.make_inputs"
    _partial_: true
    train_stream:
      - "${data.train.CreateDropInputs}"
      - "${data.Tokenize}"
      - "${data.Shuffle}"
      - "${data.PadToLength}"
      - "${data.TruncateToLength}"
      - "${data.Batch}"
    eval_stream:
      - "${data.eval.CreateDropInputs}"
      - "${data.Tokenize}"
      - "${data.Shuffle}"
      - "${data.PadToLength}"
      - "${data.TruncateToLength}"
      - "${data.Batch}"
  train:
    CreateDropInputs:
      _target_: "trax.data.CreateDropInputs"
      train: true
  eval:
    CreateDropInputs:
      _target_: "trax.data.CreateDropInputs"
      train: false
  PadToLength:
    _target_: "trax.data.PadToLength"
    len_map:
      0: 512
      1: 512
      2: 512
    pad_value:
      0: 0
      1: 0
      2: 0
  TruncateToLength:
    _target_: "trax.data.TruncateToLength"
    len_map:
      0: "(512,)"
      1: "(512,)"
      2: "(512,)"
  Batch:
    _target_: "trax.data.Batch"
    batch_size: 4
