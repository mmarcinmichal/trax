defaults:
  - /data/base
  - /data/scientific_papers/scientific_papers_base
  - _self_

data:
  train:
    TFDS:
      _target_: "trax.data.TFDS"
      dataset_name: "scientific_papers/arxiv:1.1.1"
      keys:
        - "article"
        - "abstract"
      train: true
    BucketByLength:
      _target_: "trax.data.BucketByLength"
      boundaries:
        - 16384
      batch_sizes:
        - 32
        - 1
      length_keys:
        - 0
        - 1
      strict_pad_on_len: false
  Tokenize:
    _target_: "trax.data.Tokenize"
    vocab_file: "gs://t5-data/vocabs/cc_all.32000/sentencepiece.model"
    keys:
      - 0
      - 1
    vocab_type: "sentencepiece"
  TruncateToLength:
    _target_: "trax.data.TruncateToLength"
    len_map:
      0: "(15359, )"
      1: "(1023, )"
  AppendValue:
    _target_: "trax.data.AppendValue"
    val:
      0:
        - 0
      1:
        - 1
  PadToLength:
    _target_: "trax.data.PadToLength"
    len_map:
      0: 15360
      1: 1024
    pad_value:
      0: 0
      1: 0
  Batch:
    _target_: "trax.data.Batch"
    batch_size: 4
  eval:
    TFDS:
      _target_: "trax.data.TFDS"
      dataset_name: "scientific_papers/arxiv:1.1.1"
      keys:
        - "article"
        - "abstract"
      train: false
    BucketByLength:
      _target_: "trax.data.BucketByLength"
      boundaries:
        - 16384
      batch_sizes:
        - 32
        - 1
      length_keys:
        - 0
        - 1
      strict_pad_on_len: false
  make_streams:
    _target_: "trax.data.make_streams"
    _partial_: true
    train_stream:
      - "${data.train.TFDS}"
      - "${data.Shuffle}"
      - "${data.train.BucketByLength}"
      - "${data.AddLossWeights}"
    eval_stream:
      - "${data.eval.TFDS}"
      - "${data.Shuffle}"
      - "${data.eval.BucketByLength}"
      - "${data.AddLossWeights}"
  AddLossWeights:
    _target_: "trax.data.add_loss_weights"
    _partial_: true
    id_to_mask: 0
