model:
  ReformerLM:
    _target_: "trax.models.ReformerLM"
    _partial_: true
    d_attention_key: 64
    d_attention_value: 64
    d_model: 1024
    d_ff: 4096
    dropout: 0.1
    max_len: 12288
    n_heads: 8
    n_layers: 9
    vocab_size: 256
