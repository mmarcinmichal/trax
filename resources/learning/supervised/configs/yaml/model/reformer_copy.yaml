defaults:
  - base
  - _self_

model:
  data_streams:
    _target_: "trax.models.data_streams"
    data_dir: null
    dataset_name: "copy"
  simple_sequence_copy_inputs:
    _target_: "trax.models.simple_sequence_copy_inputs"
    vocab_size: 13
    batch_size: 128
    train_length: 32
    eval_min_length: 4
    eval_max_length: 32
    pad_to_multiple: 32
  addition_inputs:
    _target_: "trax.models.addition_inputs"
    vocab_size: 13
    batch_size: 128
    train_length: 64
    eval_min_length: 32
    eval_max_length: 64
    pad_to_multiple: 32
  LSHSelfAttention:
    _target_: "trax.layers.LSHSelfAttention"
    _partial_: true
    attention_dropout: 0.0
    chunk_len: 16
    n_buckets:
      - 32
      - 32
    n_chunks_after: 0
    n_chunks_before: 1
    n_hashes: 2
    n_parallel_heads: 1
    max_length_for_buckets: 1024
    predict_mem_len: 32
    predict_drop_len: 32
  ReformerLM:
    _target_: "trax.models.ReformerLM"
    _partial_: true
    d_model: 256
    d_ff: 512
    dropout: 0.05
    max_len: 64
    n_heads: 4
    n_layers: 3
    ff_use_sru: 0
    pos_type: "fixed-base"
    attention_type: "${model.LSHSelfAttention}"
    vocab_size: 13
  TransformerLM:
    _target_: "trax.models.TransformerLM"
    d_model: 256
    d_ff: 512
    dropout: 0.05
    max_len: 32
    n_heads: 4
    n_layers: 3
    vocab_size: 13
