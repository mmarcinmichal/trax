defaults:
  - /model/base
  - _self_

model:
  PureLSHSelfAttention:
    _target_: "trax.layers.PureLSHSelfAttention"
    _partial_: true
    attention_dropout: 0.0
    chunk_len: 16
    n_buckets:
      - 32
      - 32
    n_chunks_after: 0
    n_chunks_before: 1
    n_hashes: 2
    n_parallel_heads: 1
    max_length_for_buckets: 1024
    predict_mem_len: "max_len"
    predict_drop_len: "max_len"
  PureLSHSelfAttentionWrapper:
    _target_: "trax.layers.PureLSHSelfAttentionWrapper"
    _partial_: true
    pure_lsh_implementation: "${model.PureLSHSelfAttention}"
  enc:
    PureLSHSelfAttention:
      _target_: "trax.layers.PureLSHSelfAttention"
      _partial_: true
      n_chunks_after: 1
  encoder:
    PureLSHSelfAttentionWrapper:
      _target_: "trax.layers.PureLSHSelfAttentionWrapper"
      _partial_: true
      pure_lsh_implementation: "${model.enc.PureLSHSelfAttention}"
  ConfigurableTerraformer:
    _target_: "trax.models.ConfigurableTerraformer"
    _partial_: true
    encoder_attention_type: "${model.encoder.PureLSHSelfAttentionWrapper}"
    encoder_decoder_attention_type: "${model.PureLSHSelfAttentionWrapper}"
